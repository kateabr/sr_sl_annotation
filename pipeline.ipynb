{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: run `pip install classla` to install [classla](https://github.com/clarinsi/classla)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2: download standard models and initialize pipelines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import classla\n",
    "\n",
    "# slovenian\n",
    "classla.download('sl')\n",
    "sl_nlp = classla.Pipeline('sl')\n",
    "\n",
    "# serbian\n",
    "classla.download('sr')\n",
    "sr_nlp = classla.Pipeline('sr')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3: specify input directories and match them with corresponding pipeline; check well-formedness of the files and correct if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xml.sax.handler import ContentHandler\n",
    "from xml.sax import make_parser\n",
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_data = {\"source_sl\": sl_nlp,\n",
    "              \"source_sr\": sr_nlp}\n",
    "\n",
    "def parsefile(file):\n",
    "    parser = make_parser()\n",
    "    parser.setContentHandler(ContentHandler())\n",
    "    parser.parse(file)\n",
    "\n",
    "\n",
    "for directory in input_data.keys():\n",
    "    for file in Path(directory).iterdir():\n",
    "        if not file.is_file():\n",
    "            continue\n",
    "        try:\n",
    "            etree.parse(file)\n",
    "            print(f\"✅ File {file} is well-formed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ File {file} is NOT well-formed!\\n{e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 4: process files (no changes required)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# mapping to the NCRL markdown\n",
    "to_ncrl_format = {\n",
    "    \"ADJ\": \"A\",\n",
    "    \"ADP\": \"PR\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"AUX\": \"V,aux\",\n",
    "    \"CCONJ\": \"CONJ,coord\",\n",
    "    \"DET\": \"APRO\",\n",
    "    \"INTJ\": \"INTJ\",\n",
    "    \"NOUN\": \"S\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PART\",\n",
    "    \"PRON\": \"SPRO\",\n",
    "    \"PROPN\": \"S,propn\",\n",
    "    \"SCONJ\": \"CONJ,subord\",\n",
    "    \"VERB\": \"V\",\n",
    "    \"X\": \"NONLEX\",\n",
    "    \"animacy=anim\": \"anim\",\n",
    "    \"animacy=inan\": \"inan\",\n",
    "    \"aspect=imp\": \"ipf\",\n",
    "    \"aspect=perf\": \"pf\",\n",
    "    \"case=acc\": \"acc\",\n",
    "    \"case=dat\": \"dat\",\n",
    "    \"case=gen\": \"gen\",\n",
    "    \"case=ins\": \"ins\",\n",
    "    \"case=loc\": \"loc\",\n",
    "    \"case=nom\": \"nom\",\n",
    "    \"case=voc\": \"voc\",\n",
    "    \"definite=def\": \"def\",\n",
    "    \"definite=ind\": \"indef\",\n",
    "    \"degree=cmp\": \"comp\",\n",
    "    \"degree=pos\": None,\n",
    "    \"degree=sup\": \"supr\",\n",
    "    \"foreign=yes\": None,\n",
    "    \"gender=fem\": \"f\",\n",
    "    \"gender=masc\": \"m\",\n",
    "    \"gender=neut\": \"n\",\n",
    "    \"gender[psor]=fem\": \"poss:f\",\n",
    "    \"gender[psor]=masc\": \"poss:m\",\n",
    "    \"gender[psor]=masc,neut\": \"poss:m/n\",\n",
    "    \"number[psor]=dual\": \"poss:du\",\n",
    "    \"number[psor]=plur\": \"poss:pl\",\n",
    "    \"number[psor]=sing\": \"poss:sg\",\n",
    "    \"mood=cnd\": \"cond\",\n",
    "    \"mood=imp\": \"imper\",\n",
    "    \"mood=ind\": \"indic\",\n",
    "    \"number=dual\": \"du\",\n",
    "    \"number=plur\": \"pl\",\n",
    "    \"number=sing\": \"sg\",\n",
    "    \"numform=digit\": \"ciph\",\n",
    "    \"numform=mult\": \"coll\",\n",
    "    \"numform=word\": None,\n",
    "    \"numtype=card\": None,\n",
    "    \"numtype=mult\": \"coll\",\n",
    "    \"numtype=ord\": None,\n",
    "    \"person=1\": \"1p\",\n",
    "    \"person=2\": \"2p\",\n",
    "    \"person=3\": \"3p\",\n",
    "    \"polarity=neg\": \"neg\",\n",
    "    \"polarity=pos\": \"pos\",\n",
    "    \"poss=yes\": \"poss\",\n",
    "    \"prontype=dem\": \"dem\",\n",
    "    \"prontype=ind\": \"ind\",\n",
    "    \"prontype=int,rel\": \"interr,rel\",\n",
    "    \"prontype=int\": \"interr\",\n",
    "    \"prontype=neg\": \"neg\",\n",
    "    \"prontype=prs\": \"pers\",\n",
    "    \"prontype=rel\": \"rel\",\n",
    "    \"prontype=tot\": \"tot\",\n",
    "    \"reflex=yes\": \"refl\",\n",
    "    \"tense=fut\": \"fut\",\n",
    "    \"tense=past\": \"praet\",\n",
    "    \"tense=pres\": \"praes\",\n",
    "    \"variant=bound\": \"pr-pro\",\n",
    "    \"variant=short\": \"brev\",\n",
    "    \"verbform=conv\": \"ger\",\n",
    "    \"verbform=fin\": None,\n",
    "    \"verbform=inf\": \"inf\",\n",
    "    \"verbform=part\": \"partcp\",\n",
    "    \"verbform=sup\": \"sup\",\n",
    "    \"voice=act\": \"act\",\n",
    "    \"voice=pass\": \"pass\"\n",
    "}\n",
    "\n",
    "if_present_delete = {\n",
    "    \"gender[psor]=masc\": \"neut\"\n",
    "}\n",
    "\n",
    "def map_to_ncrl(pos, attrs):\n",
    "    res_attrs = set([])\n",
    "    res_pos = pos\n",
    "    for attr_pair_str in attrs.lower().split(\"|\"):\n",
    "        if attr_pair_str == \"numform=ord\" and res_pos == \"ADJ\":\n",
    "            res_pos = \"ANUM\"\n",
    "        elif attr_pair_str == \"foreign=yes\":\n",
    "            res_pos = \"NONLEX\"\n",
    "        elif attr_pair_str in if_present_delete.keys():\n",
    "            if if_present_delete[attr_pair_str] in res_attrs:\n",
    "                res_attrs.remove(if_present_delete[attr_pair_str])\n",
    "            else:\n",
    "                to_ncrl_format[if_present_delete[attr_pair_str]] = None\n",
    "        if attr_pair_str not in to_ncrl_format.keys():\n",
    "            print(f\"unmapped attribute: {attr_pair_str}\")\n",
    "            res_attrs.add(attr_pair_str)\n",
    "        elif to_ncrl_format[attr_pair_str] is not None:\n",
    "            res_attrs.add(to_ncrl_format[attr_pair_str])\n",
    "    return res_pos, \",\".join(res_attrs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cyrtranslit\n",
    "\n",
    "known_keys = [\"feats\"]\n",
    "keys_to_ignore = [\"id\", \"text\", \"lemma\", \"upos\", \"xpos\", \"head\", \"ner\", \"deprel\"]\n",
    "\n",
    "def add_space_after(token_dict):\n",
    "    return not (\"misc\" in token_dict.keys() and \"SpaceAfter=No\" in token_dict[\"misc\"])\n",
    "\n",
    "def annotate(ana_node, token_dict):\n",
    "    pos = \"\"\n",
    "    attrs = \"\"\n",
    "    for key, value in token_dict.items():\n",
    "        if key not in keys_to_ignore:\n",
    "            if key not in known_keys:\n",
    "                if key != \"misc\" and value != \"SpaceAfter=No\":\n",
    "                    print(f\"{key} :: {value} in {token_dict}\")\n",
    "            else:\n",
    "                pos, attrs = map_to_ncrl(token_dict[\"upos\"], value)\n",
    "    if attrs != \"\":\n",
    "        ana_node.attrib[\"gr\"] = pos\n",
    "    else:\n",
    "        ana_node.attrib[\"gr\"] = f\"{pos},{attrs}\"\n",
    "\n",
    "def append_text(root, text):\n",
    "    if len(root.getchildren()) > 0:\n",
    "        node = last_child(root)\n",
    "        if node.tail is None:\n",
    "            node.tail = text\n",
    "        else:\n",
    "            node.tail += text\n",
    "    else:\n",
    "        if root.text is None:\n",
    "            root.text = text\n",
    "        else:\n",
    "            root.text += text\n",
    "\n",
    "def last_child(node):\n",
    "    return node.getchildren()[-1]\n",
    "\n",
    "for directory, pipeline in input_data.items():\n",
    "    for filename in Path(directory).iterdir():\n",
    "        parsed_file = etree.parse(filename)\n",
    "        bar_format = \"File: \" + filename.name + \" |{bar}| {percentage:3.0f}% {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]\"\n",
    "        for para in tqdm(parsed_file.find(\"body\"), bar_format=bar_format):\n",
    "            if para.tag != \"para\":\n",
    "                print(f\"Incorrect sentence pair tag: {para.tag}\")\n",
    "            for sentence in para:\n",
    "                if sentence.tag != \"se\":\n",
    "                    print(f\"Incorrect sentence tag: {sentence.tag}\")\n",
    "                if sentence.get(\"lang\") == \"rus\" or sentence.text is None:\n",
    "                    continue\n",
    "                tokenized_sentence = etree.Element(\"se\", attrib={\"lang\": sentence.get(\"lang\")})\n",
    "                if sentence.get(\"lang\") == \"srp\":\n",
    "                    parsed_sentence = pipeline(cyrtranslit.to_latin(sentence.text, \"sr\"))\n",
    "                else:\n",
    "                    parsed_sentence = pipeline(sentence.text)\n",
    "                if all(token.to_dict()[0][\"upos\"] in [\"PUNCT\", \"X\"] for token in parsed_sentence.iter_tokens()):\n",
    "                    # no markdown required for non-textual sentences\n",
    "                    continue\n",
    "                for token in parsed_sentence.iter_tokens():\n",
    "                    token_dict = token.to_dict()[0]\n",
    "                    if token_dict[\"upos\"] == \"PUNCT\":\n",
    "                        append_text(tokenized_sentence, token.text)\n",
    "                    else:\n",
    "                        tokenized_sentence.append(etree.Element(\"w\"))\n",
    "                        word_token = last_child(tokenized_sentence)\n",
    "                        word_token.append(etree.Element(\"ana\", attrib={\"lex\": token_dict[\"lemma\"]}))\n",
    "                        ana = last_child(word_token)\n",
    "                        ana.tail = token_dict[\"text\"]\n",
    "                        annotate(ana, token_dict)\n",
    "                    if add_space_after(token_dict):\n",
    "                        append_text(tokenized_sentence, \" \")\n",
    "\n",
    "                sentence.getparent().replace(sentence, tokenized_sentence)\n",
    "\n",
    "        if not Path(\"annotated\").exists():\n",
    "            Path.mkdir(Path(\"annotated\"))\n",
    "        if not Path(\"annotated\").joinpath(directory).exists():\n",
    "            Path.mkdir(Path(\"annotated\").joinpath(directory))\n",
    "        with open(Path(\"annotated\").joinpath(filename), \"bw\") as annotated_file:\n",
    "            annotated_file.write(etree.tostring(parsed_file, encoding=\"utf-8\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 5: check well-formedness of the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for directory in input_data.keys():\n",
    "    for file in Path(\"annotated\").joinpath(directory).iterdir():\n",
    "        if not file.is_file():\n",
    "            continue\n",
    "        try:\n",
    "            etree.parse(file)\n",
    "            print(f\"✅ File {file} is well-formed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ File {file} is NOT well-formed!\\n{e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}